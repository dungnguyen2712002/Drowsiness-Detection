{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "454e0ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from preprocess_data import filter_col, get_table\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57ef8bbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(os.path.join('output', 'csv', '43_5.csv'))\n",
    "print((df['px_1'] != -1).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "458eceab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_csv(file):\n",
    "    df = pd.read_csv(file)\n",
    "    return False if (df['px_1'] != -1).sum() <= 1 \\\n",
    "    else True\n",
    "    \n",
    "files = glob.glob(os.path.join('output', 'csv', '*.csv'))\n",
    "valid_file = list(filter(check_csv, files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a7ed5fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_participants(files):\n",
    "    return [os.path.basename(file).split('.')[0] for file in files]\n",
    "\n",
    "valid_index = extract_participants(valid_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "35e9e26e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['03_10',\n",
       " '03_5',\n",
       " '05_10',\n",
       " '08_0',\n",
       " '08_5',\n",
       " '10_10',\n",
       " '10_5',\n",
       " '17_0',\n",
       " '17_5',\n",
       " '18_0',\n",
       " '18_10',\n",
       " '18_5',\n",
       " '23_5',\n",
       " '26_0',\n",
       " '26_10',\n",
       " '27_0',\n",
       " '27_10',\n",
       " '28_10',\n",
       " '28_5',\n",
       " '31_0',\n",
       " '31_10',\n",
       " '31_5',\n",
       " '32_0',\n",
       " '32_10_1',\n",
       " '32_10_2',\n",
       " '32_5',\n",
       " '34_0',\n",
       " '34_10',\n",
       " '34_5',\n",
       " '35_0',\n",
       " '35_10',\n",
       " '35_5',\n",
       " '36_0',\n",
       " '36_10',\n",
       " '36_5',\n",
       " '37_0',\n",
       " '37_10',\n",
       " '37_5',\n",
       " '39_0',\n",
       " '39_10',\n",
       " '39_5',\n",
       " '40_0',\n",
       " '40_10',\n",
       " '40_5',\n",
       " '41_0',\n",
       " '41_5',\n",
       " '44_0',\n",
       " '44_10',\n",
       " '45_0',\n",
       " '45_10',\n",
       " '45_5',\n",
       " '46_10',\n",
       " '46_5',\n",
       " '48_10',\n",
       " '48_5',\n",
       " '49_0',\n",
       " '49_10_1',\n",
       " '50_10',\n",
       " '50_5',\n",
       " '51_0',\n",
       " '51_10',\n",
       " '51_5',\n",
       " '60_0',\n",
       " '60_10',\n",
       " '60_5']"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(valid_index))\n",
    "valid_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1864b17e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_data(index, frame_to_keep=150, start=150, \n",
    "         train_percentage=17/22, base_path=None):\n",
    "    df = get_table(index)\n",
    "    df = filter_col(df)\n",
    "    df.drop(df.columns[0], axis=1, inplace=True)\n",
    "    train_index = int((len(df)-start)*train_percentage)\n",
    "    print(f'{index}: {df.isnull().sum().sum()}')\n",
    "    # get 4 features of each frame in 150 consecutive frames (15s)\n",
    "    # and concat it into a vector\n",
    "    X = [df[index-frame_to_keep:index].to_numpy().reshape(frame_to_keep*4)\n",
    "              for index in range(start, len(df))]\n",
    "    mood = index.split('_')[1]\n",
    "    y = np.full((len(df)-start, 1), mood, dtype=int).squeeze()\n",
    "    y[y != 0] = 1\n",
    "    X_train = np.array(X[:train_index])\n",
    "    X_test = np.array(X[train_index:])\n",
    "    \n",
    "    y_train = y[:train_index]\n",
    "    y_test = y[train_index:]\n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52486df8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, X_train, y_train, X_test, y_test):\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    print('Accuracy:', f'{acc*100}%')\n",
    "    print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a10a0d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(model, val=valid_index):\n",
    "    X_train = []\n",
    "    y_train = []\n",
    "    X_test = []\n",
    "    y_test = []\n",
    "    for index in val:\n",
    "        X_train1, y_train1, X_test1, y_test1 = create_data(index)\n",
    "        \n",
    "        X_train += [X_train1]\n",
    "        y_train += [y_train1]\n",
    "        X_test += [X_test1]\n",
    "        y_test += [y_test1]\n",
    "        \n",
    "\n",
    "    X_train = np.concatenate(X_train, axis = 0)\n",
    "    y_train = np.concatenate(y_train, axis = 0)\n",
    "    X_test = np.concatenate(X_test, axis = 0)\n",
    "    y_test = np.concatenate(y_test, axis = 0)\n",
    "    \n",
    "    print(f'Train data: {X_train.shape}')\n",
    "    print(f'Test data: {X_test.shape}')\n",
    "    \n",
    "    train(model, X_train, y_train, X_test, y_test)\n",
    "    return model, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "357c2bd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline(model, index=valid_index):\n",
    "    X_train = ()\n",
    "    y_train = ()\n",
    "    X_test = ()\n",
    "    y_test = ()\n",
    "    for index in valid_index:\n",
    "        X_train1, y_train1, X_test1, y_test1 = create_data(participant, 0)\n",
    "        X_train2, y_train2, X_test2, y_test2 = create_data(participant, 5)\n",
    "        X_train3, y_train3, X_test3, y_test3 = create_data(participant, 10)\n",
    "        \n",
    "        X_train += (X_train1, X_train2, X_train3)\n",
    "        y_train += (y_train1, y_train2, y_train3)\n",
    "        X_test += (X_test1, X_test2, X_test3)\n",
    "        y_test += (y_test1, y_test2, y_test3)\n",
    "        \n",
    "\n",
    "    X_train = np.concatenate(X_train, axis = 0)\n",
    "    y_train = np.concatenate(y_train, axis = 0)\n",
    "    X_test = np.concatenate(X_test, axis = 0)\n",
    "    y_test = np.concatenate(y_test, axis = 0)\n",
    "    \n",
    "    train(model, X_train, y_train, X_test, y_test)\n",
    "    return model, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0f7980d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "03_10: 0\n",
      "03_5: 0\n",
      "05_10: 0\n",
      "08_0: 0\n",
      "08_5: 0\n",
      "10_10: 0\n",
      "10_5: 0\n",
      "17_0: 0\n",
      "17_5: 0\n",
      "18_0: 0\n",
      "18_10: 0\n",
      "18_5: 0\n",
      "23_5: 0\n",
      "26_0: 0\n",
      "26_10: 0\n",
      "27_0: 0\n",
      "27_10: 0\n",
      "28_10: 0\n",
      "28_5: 0\n",
      "31_0: 0\n",
      "31_10: 0\n",
      "31_5: 0\n",
      "32_0: 0\n",
      "32_10_1: 0\n",
      "32_10_2: 0\n",
      "32_5: 0\n",
      "34_0: 0\n",
      "34_10: 0\n",
      "34_5: 0\n",
      "35_0: 0\n",
      "35_10: 0\n",
      "35_5: 0\n",
      "36_0: 0\n",
      "36_10: 0\n",
      "36_5: 0\n",
      "37_0: 0\n",
      "37_10: 0\n",
      "37_5: 0\n",
      "39_0: 0\n",
      "39_10: 0\n",
      "39_5: 0\n",
      "40_0: 0\n",
      "40_10: 0\n",
      "40_5: 0\n",
      "41_0: 0\n",
      "41_5: 0\n",
      "44_0: 0\n",
      "44_10: 0\n",
      "45_0: 0\n",
      "45_10: 0\n",
      "45_5: 0\n",
      "46_10: 0\n",
      "46_5: 0\n",
      "48_10: 0\n",
      "48_5: 0\n",
      "49_0: 0\n",
      "49_10_1: 0\n",
      "50_10: 0\n",
      "50_5: 0\n",
      "51_0: 0\n",
      "51_10: 0\n",
      "51_5: 0\n",
      "60_0: 0\n",
      "60_10: 0\n",
      "60_5: 0\n",
      "Train data: (138902, 600)\n",
      "Test data: (40877, 600)\n",
      "Accuracy: 67.37529662157203%\n",
      "[[ 1575 10137]\n",
      " [ 3199 25966]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "svm = SVC()\n",
    "\n",
    "model, X_test, y_test = pipeline(svm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26582c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'final_model.sav'\n",
    "pickle.dump(model, open(filename, 'wb'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
